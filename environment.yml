name: llama-text-detection
channels:
  - nvidia/label/cuda-12.1.1
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - _openmp_mutex=5.1=1_gnu
  - bzip2=1.0.8=h7b6447c_0
  - ca-certificates=2023.08.22=h06a4308_0
  - cuda-nvcc=12.1.105=0
  - ld_impl_linux-64=2.38=h1181459_1
  - libffi=3.4.4=h6a678d5_0
  - libgcc-ng=11.2.0=h1234567_1
  - libgomp=11.2.0=h1234567_1
  - libstdcxx-ng=11.2.0=h1234567_1
  - libuuid=1.41.5=h5eee18b_0
  - ncurses=6.4=h6a678d5_0
  - openssl=3.0.10=h7f8727e_2
  - pip=23.0.1=py310h06a4308_0
  - python=3.10.11=h955ad1f_3
  - readline=8.2=h5eee18b_0
  - setuptools=67.8.0=py310h06a4308_0
  - sqlite=3.41.2=h5eee18b_0
  - tk=8.6.12=h1ccaba5_0
  - tzdata=2023c=h04d1e81_0
  - wheel=0.38.4=py310h06a4308_0
  - xz=5.4.2=h5eee18b_0
  - zip=3.0=h7f8727e_1
  - zlib=1.2.13=h5eee18b_0
  - pip:
    - torch==2.0.1+cu121               # Ensure CUDA compatibility
    - transformers==4.29.0
    - datasets==2.12.0
    - scikit-learn==1.3.1
    - matplotlib==3.7.1
    - tqdm==4.65.0
    - accelerate==0.18.0               # For efficient model training
    - sentencepiece==0.1.99            # For LLaMA tokenization compatibility
    - einops==0.6.1                    # Helper for tensor manipulation
    - wandb==0.15.4                    # For logging experiments, optional
    - huggingface-hub==0.16.4          # Accessing models and datasets
    - python-dotenv==1.0.0             # For environment variable management (optional)
    - protobuf==4.23.2
    - psutil==5.9.5                    # For system monitoring
    - pandas==1.5.3
    - seaborn==0.12.2                  # For advanced data visualizations
    - filelock==3.9.0
    - requests==2.31.0
